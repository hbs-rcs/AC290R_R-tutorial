---
title: Data Transformation
slug: data-transformation
author: Data Carpentry contributors, Michael Levy, Bob Freeman, & Andrew Marder
minutes: 45
weight: 30
---

```{r, eval=TRUE, echo=FALSE}
# get our document in shape to run examples
gapminder <- read.csv('data/gapminder-FiveYearData.csv', stringsAsFactors = FALSE)
gapminder$continent <- factor(gapminder$continent, 
                               levels=c("Europe", "Americas", "Asia", "Africa", "Oceana"))
```
------------


> ## Learning objectives {.objectives}
>
> - Be able to use the six major dplyr verbs (`filter`, `select`, `arrange`, `mutate`, `group_by`, `summarize`)
> - Be able to use and understand the advantages of the `magrittr` pipe: `%>%`
>


------------

# Data manipulation using dplyr


It is an often bemoaned fact that a data scientist spends much, and often most, of her time wrangling data: getting it organized and clean. Bracket subsetting is handy, but it can be cumbersome and difficult to read,
especially for complicated operations. In this lesson we will learn an efficient set of tools that can handle the vast majority of most data management tasks. 

 Enter `dplyr`, a package for making data manipulation easier.

Packages in R are basically sets of additional functions that let you do more
stuff in R. The functions we've been using, like `str()`, come built into R;
packages give you access to more functions. You need to install a package and
then load it to be able to use it.

```{r, eval = FALSE, purl = FALSE}
install.packages("dplyr") ## install
```

You might get asked to choose a CRAN mirror -- this is basically asking you to
choose a site to download the package from. The choice doesn't matter too much;
I'd recommend choosing the RStudio mirror.

```{r, message = FALSE, purl = FALSE}
library("dplyr")          ## load
```

You only need to install a package once per computer, but you need to load it
every time you open a new R session and want to use that package.

## What is dplyr?

The package `dplyr` is a fairly new (2014) package that tries to provide easy
tools for the most common data manipulation tasks. It is built to work directly
with data frames. The thinking behind it was largely inspired by the package
`plyr` which has been in use for some time but suffered from being slow in some
cases.` dplyr` addresses this by porting much of the computation to C++. An
additional feature is the ability to work with data stored directly in an
external database. The benefits of doing this are that the data can be managed
natively in a relational database, queries can be conducted on that database,
and only the results of the query returned.

This addresses a common problem with R in that all operations are conducted in
memory and thus the amount of data you can work with is limited by available
memory. The database connections essentially remove that limitation in that you
can have a database of many 100s GB, conduct queries on it directly and pull
back just what you need for analysis in R.


## The tasks of `dplyr`

There are five actions we often want to apply to a tabular dataset:

- Filter rows
- Filter columns
- Arrange rows
- Make new columns
- Summarize groups

We are about to see how to do each of those things using the `dplyr` package. Everything we're going to learn to do can also be done using "base R", but `dplyr` makes it easier, and the syntax is consistent, and it actually makes the computations faster. 


### `filter()`

Suppose we want to see just the gapminder data for the USA. First, we need to know how "USA" is written in the dataset: Is it USA or United States or what? We can see all the unique values of a variable with the `unique` function.

```{r unique}
unique(gapminder$country)
```

Okay, now we want to see just the rows of the data.frame where country is "United States". The syntax for all `dplyr` functions is the same: The first argument is the data.frame, the rest of the arguments are whatever you want to do in that data.frame. 

```{r filter}
filter(gapminder, country == "United States")
```

We can also apply multiple conditions, e.g. the US after 2000:

```{r filter and}
filter(gapminder, country == "United States" & year > 2000)
```

We can also use "or" conditions with the vertical pipe: `|`. Notice that the variable (column) names don't go in quotes, but values of character variables do. 

```{r filter or}
filter(gapminder, country == "United States" | country == "Mexico")
```

A good, handy reference list for the operators (and, or, etc) can be found [here](http://www.statmethods.net/management/operators.html).

### `select()`

`filter` returned a subset of the data.frame's rows. `select` returns a subset of the data.frame's columns.

Suppose we only want to see country and life expectancy. 

```{r select, eval = FALSE}
select(gapminder, country, lifeExp)
```

Hmm, we can't really see all 1704 rows. We can just look at the top of the data.frame with the `head` function. We could assign the output of our `select` command to a new variable and display the head of that, or we can wrap our select function in `head`. Note that if we don't assign the output of a function to a variable, the output is printed, but nothing changes. E.g. the last command didn't remove the other columns from the gapminder data.frame, it just printed the results of that function call. Understand how the nesting functions works: `head` expects a data.frame as its argument, and `select` returns a data.frame. The output of `select` becomes the input to `head`.

```{r select head}
gapCountryExp <- select(gapminder, country, lifeExp)
head(gapCountryExp)
head(select(gapminder, country, lifeExp))
```

### `arrange()`

You can order the rows of a data.frame by a variable using `arrange`. Suppose we want to see the most populous countries. Again, we wrap the results in `head` to just print the first few rows: 

```{r arrange}
head(arrange(gapminder, pop))
```

Hmm, we didn't get the most populous countries. By default, `arrange` sorts the variable in *increasing* order. We could see the most populous countries by examining the `tail` of the last command, or we can sort the data.frame by descending population by wrapping the variable in `desc()`:

```{r arrange desc}
head(arrange(gapminder, desc(pop)))
```

`arrange` can also sort by multiple variables. It will sort the data.frame by the first variable, and if there are any ties in that variable, they will be sorted by the next variable, and so on. Here we sort from newest to oldest, and within year from richest to poorest:

```{r arrange multi}
head(arrange(gapminder, desc(year), desc(gdpPercap)))
```

**Shoutout Q: Would we get the same output if we switched the order of `desc(year)` and `desc(gdpPercap)` in the last line?**


## Pipes


Suppose we want to look at all the countries where life expectancy is greater than 80 years, sorted from poorest to richest. First, we `filter`, then we `arrange`. Each function expects a data.frame as its first argument and returns a data.frame as its output. So we could wrap them like we did with `head(select( ... ))` above: 

```{r filter and arrange}
arrange(filter(gapminder, lifeExp > 80), gdpPercap)
```

Or, we could assign the intermediate data.frame to a variable:

```{r filter and arrange assign}
lifeExpGreater80 <- filter(gapminder, lifeExp > 80)
arrange(lifeExpGreater80, gdpPercap)
```

The first option is difficult to read, and the second option clutters our Environment with a data.frame that we will only use once. This is especially true if we need to do multiple operations:

```{r}
gapCountryExp <- select(gapminder, country, lifeExp)
gapCountryExpFilter <- filter(gapCountryExp, lifeExp > 80)
gapCountryExpFilterSorted <- arrange(gapCountryExpFilter, lifeExp)
gapCountryExpFilterSorted 
```

or

```{r}
arrange(filter(select(gapminder, country, lifeExp), lifeExp > 80), lifeExp)
```

Eeewww! Environment clutter, or obfuscated code? There is a better way, which makes both writing and reading the code easier. The pipe from the `magrittr` package (which is automatically installed and loaded with `dplyr`) takes the output of first line, and plugs it in as the first argument of the next line.

```{r filter and arrange pipe}
filter(gapminder, lifeExp > 80) %>%
    arrange(gdpPercap)
```

Another way to write this is

```{r pipe}
gapminder %>%
    filter(lifeExp > 80) %>%
    arrange(gdpPercap)
```

Whatever goes through the pipe becomes the first argument of the function after the pipe. This is convenient, because all `dplyr` functions produce a data.frame as their output and take a data.frame as the first argument. Since R ignores white-space, we can put each function on a new line, which RStudio will automatically indent, making everything easy to read. Now each line represents a step in a sequential operation. You can read this as "Take the gapminder data.frame, filter to the rows where lifeExp is greater than 80, and arrange by gdpPercap." 

**Shoutout Q: How would we modify this if we wanted to include the select statement as in the 3rd bad example above?**

Making your code easier for humans to read will save you lots of time. The human reading it is usually future-you, and operations that seem simple when you're writing them will look like gibberish when you're three weeks removed from them, let alone three months or three years or another person. Make your code as easy to read as possible by using the pipe where appropriate, leaving white space, using descriptive variable names, being consistent with spacing and naming, and liberally commenting code.

If we wanted to create a new object with this smaller version of the data we
could do so by assigning it a new name:

```{r pipe assign}
lifeExpGreater80 <- gapminder %>% 
    filter(lifeExp > 80) %>%
    arrange(gdpPercap)

lifeExpGreater80
```

> #### Data Reduction {.challenge}
>
> 1. Produce a data.frame with only the names and years of countries where the life expectancy is
> less than 70, from highest to lowest.
> 2. Do this same operation again though only for African and Oceanic countries, 
> sorted by the year from most- to least-recent.
>

## More tasks of `dplyr`

### `mutate()`

We have learned how to drop rows, drop columns, and rearrange rows. To make a new column we use the `mutate` function. As usual, the first argument is a data.frame. The second argument is the name of the new column you want to create, followed by an equal sign, followed by what to put in that column. You can reference other variables in the data.frame, and `mutate` will treat each row independently. E.g. we can calculate the total GDP of each country in each year by multiplying the per-capita GDP by the population. We pass the output of `mutate` to `head` to keep the display under control. Pipes work with non-dplyr
functions too, as long as the `dplyr` or `magrittr` packages are loaded.

How would we view the highest-total-gdp countries?

```{r mutate}
mutate(gapminder, total_gdp = gdpPercap * pop) %>%
    head()
```

You can create multiple columns in the same function call, separating them by commas. E.g. suppose we want the base-10 logarithm of each country's population and per-capita gdp:

```{r mutate 2}
gapminder %>%
    mutate(log_gdp = log10(gdpPercap), log_pop = log10(pop)) %>%
    arrange(desc(log_gdp)) %>%
    head()
```

> #### MCQ: Data Reduction {.challenge}
>
> Produce a data.frame with only the names and years of countries where per capita gdp is less than a dollar a day sorted from most- to least-recent.
>
> - Tip: The `gdpPercap` variable is annual gdp. You'll need to adjust.
> - Tip: For complex tasks, it often helps to use pencil and paper to write/draw/map the various steps needed and how they fit together before writing any code.
> 
> What is the annual per-capita gdp, rounded to the nearest dollar, of the first row in the data.frame?
>
> a. $278
> b. $312
> c. $331
> d. $339


### `group_by()` and `summarize()`

Often we want to calculate a new variable, but rather than keeping each row as an independent observation, we want to group observations together to calculate some summary statistic. To do this we need two functions, one to do the grouping and one to calculate the summary statistic: `group_by` and `summarize`. By itself `group_by` doesn't change a data.frame; it just sets up the grouping. `summarize` then goes over each group in the data.frame and does whatever calculation you want. E.g. suppose we want the average global gdp for each year. While we're at it, let's calculate the mean and median and see how they differ. 

```{r summarize}
gapminder %>%
    group_by(year) %>%
    summarize(mean_gdp = mean(gdpPercap), median_gdp = median(gdpPercap))
```

Note that `summarize()` eliminates any other columns. Why?


There are several different summary statistics that can be generated from our data. The R base package provides many built-in functions such as `mean`, `median`, `min`, `max`, and `range`.  By default, all **R functions operating on vectors that contains missing data will return NA**. It's a way to make sure that users know they have missing data, and make a conscious decision on how to deal with it. When dealing with simple statistics like the mean, the easiest way to ignore `NA` (the missing data) is to use `na.rm=TRUE` (`rm` stands for remove). An alternate option is to use the function `is.na()`, which evaluates to true if the value
passed to it is not a number. This function is more useful as a part of a filter, where you
can filter out everything that is not a number. For that purpose you would do something like

```{r, purl = FALSE, eval=FALSE}
gapminder %>%
  filter(!is.na(someColumn)) %>%
  head
```

The `!` symbol negates it, so we're asking for everything that is not an `NA`. 


We often want to calculate the number of entries within a group. E.g. we might wonder if our dataset is balanced by country. We can do this with the `n()` function, or `dplyr` provides a `count` function as a convenience:

```{r count}
gapminder %>%
    group_by(country) %>%
    summarize(number_entries = n())
count(gapminder, country)
```

The highly observant will notice the output of this looks a little different than most of our data.frames -- why didn't it print out all 60 rows, and what's with that header info at the top? `dplyr` converted the data.frame to a table-data.frame, or `tbl_df` object. The most salient difference between them is that `tbl_df`s never print more than a few rows, which can be nice. If you like this behavior, you can convert any data.frame to a tbl_df like so:

```{r}
gapminder <- tbl_df(gapminder)
gapminder
```
Now it prints nicely, so we don't need to use `head`.

We can also do multiple groupings. Suppose we want the maximum life expectancy in each continent for each year. We group by continent and year and calculate the maximum with the `max` function:

```{r multiple groups}
gapminder %>%
    group_by(continent, year) %>%
    summarize(longest_life = max(lifeExp))
```

Hmm, we got the longest life expectancy for each continent-year, but we didn't get the country. To get the country, we have to ask R "Where lifeExp is at a maximum, what is the entry in country?" For that we use the `which.max` function. `max` returns the maximum value; `which.max` returns the location of the maximum value. That is illustrated in the following example:

```{r which.max}
max(c(1, 7, 4))
which.max(c(1, 7, 4))
```

Now, back to the question: Where lifeExp is at a maximum, what is the entry in country? 

```{r which.max lifeExp}
gapminder %>%
    group_by(continent, year) %>%
    summarize(longest_life = max(lifeExp), country = country[which.max(lifeExp)])
```


> #### Challenge -- Part 1 {.challenge}
>
> - Calculate a new column: the total GDP of each country in each year. 
> - Calculate the variance -- `var()` of countries' gdps in each year.
> - Is country-level GDP getting more or less equal over time?
> 

> #### Challenge -- Part 2 {.challenge}
> 
> - Modify the code you just wrote to calculate the variance in both country-level GDP and per-capita GDP.
> - Do both measures support the conclusion you arrived at above?
> 


## Resources

That is the core of `dplyr`'s functionality, but it does more. RStudio makes a great [cheatsheet](https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf) that covers all the `dplyr` functions we just learned, plus what we will learn in the next lesson: keeping data tidy.


